{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集的 batch 数量: 938，每个 batch 中的数据数量: 64\n",
      "测试集的 batch 数量: 157，每个 batch 中的数据数量: 64\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "# 数据集的路径\n",
    "path = \"./DataSet\"\n",
    "# 使用的设备\n",
    "device = torch.device(\"cuda\")\n",
    "# 数据预处理,转换为张量并归一化\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),  # 将图像转换为张量\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ]\n",
    ")  # 归一化处理\n",
    "# 将数据集使用预处理定义好的 transform\n",
    "train_set = MNIST(root=path, train=True, download=True, transform=transform)\n",
    "test_set = MNIST(root=path, train=False, download=True, transform=transform)\n",
    "# 加载数据集并设置批次大小\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=False)\n",
    "# 修正 print 语句，明确输出内容\n",
    "print(\n",
    "    f\"训练集的 batch 数量: {len(train_loader)}，每个 batch 中的数据数量: {train_loader.batch_size}\"\n",
    ")\n",
    "print(\n",
    "    f\"测试集的 batch 数量: {len(test_loader)}，每个 batch 中的数据数量: {test_loader.batch_size}\"\n",
    ")\n",
    "\n",
    "# 图片可视化\n",
    "# import matplotlib.pyplot as plt\n",
    "# # 获取一个批次的数据\n",
    "# images, labels = next(iter(train_loader))\n",
    "\n",
    "# #展示图片\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for i in range(25):\n",
    "#     plt.subplot(5, 5, i + 1)\n",
    "#     # 确保图像数据形状正确\n",
    "#     img = images[i].squeeze().numpy()\n",
    "#     plt.imshow(img, cmap='gray')\n",
    "#     plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import Flatten\n",
    "from torch.nn import Linear\n",
    "from torch.nn.init import xavier_uniform_\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "\n",
    "# 定义 MNIST_Net 类，继承自 PyTorch 的 Module 类\n",
    "\n",
    "\n",
    "class MNIST_Net(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 卷积层 1：输入通道数为 1，输出通道数为 32，卷积核大小为 3x3\n",
    "        self.conv1 = Conv2d(1, 32, (3, 3))\n",
    "        # 使用 Kaiming 初始化方法初始化卷积层 1 的权重，适用于 ReLU 激活函数\n",
    "        kaiming_uniform_(self.conv1.weight, nonlinearity=\"relu\")\n",
    "        self.act1 = ReLU()\n",
    "        # 池化层 1：使用 2x2 的最大池化，步长为 2\n",
    "        self.pool1 = MaxPool2d((2, 2), stride=(2, 2))\n",
    "        # 卷积层 2：输入通道数为 32，输出通道数为 32，卷积核大小为 3x3\n",
    "        self.conv2 = Conv2d(32, 32, (3, 3))\n",
    "        # 使用 Kaiming 初始化方法初始化卷积层 2 的权重，适用于 ReLU 激活函数\n",
    "        kaiming_uniform_(self.conv2.weight, nonlinearity=\"relu\")\n",
    "        self.act2 = ReLU()\n",
    "        # 池化层 2：使用 2x2 的最大池化，步长为 2\n",
    "        self.pool2 = MaxPool2d((2, 2), stride=(2, 2))\n",
    "        # Flatten 层：将二维特征图展平为一维向量\n",
    "        self.flatten = Flatten()\n",
    "        # 全连接层 1：输入维度为计算得到的值，输出维度为 100\n",
    "        self.fc1 = Linear(5 * 5 * 32, 100)\n",
    "        # 使用 Kaiming 初始化方法初始化全连接层 1 的权重，适用于 ReLU 激活函数\n",
    "        kaiming_uniform_(self.fc1.weight, nonlinearity=\"relu\")\n",
    "        self.act3 = ReLU()\n",
    "        # 全连接层 2：输入维度为 100，输出维度为 10，对应 MNIST 的 10 个类别\n",
    "        self.fc2 = Linear(100, 10)\n",
    "        # 使用 Xavier 初始化方法初始化全连接层 2 的权重\n",
    "        xavier_uniform_(self.fc2.weight)\n",
    "\n",
    "    # 前向传播\n",
    "    def forward(self, x):\n",
    "        # 卷积层 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.act1(x)\n",
    "        # 池化层 1\n",
    "        x = self.pool1(x)\n",
    "        # 卷积层 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.act2(x)\n",
    "        # 池化层 2\n",
    "        x = self.pool2(x)\n",
    "        # 使用 Flatten 层扁平化\n",
    "        x = self.flatten(x)\n",
    "        # 全连接层\n",
    "        x = self.fc1(x)\n",
    "        x = self.act3(x)\n",
    "        # 输出层\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD\n",
    "\n",
    "\n",
    "# 训练模型\n",
    "def train_model(train_loader, model):\n",
    "    # 定义损失函数和优化器\n",
    "    criterion = CrossEntropyLoss()\n",
    "    optimizer = SGD(model.parameters(), lr=0.01)\n",
    "    num_epochs = 10  # 训练的轮数\n",
    "    running_loss = 0.0  # 初始化 running_loss\n",
    "    # 遍历epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        # 遍历训练数据\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            # 将数据移动到GPU\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # 梯度清零\n",
    "            optimizer.zero_grad()\n",
    "            # 计算模型输出\n",
    "            y_hat = model(inputs)\n",
    "            # 计算损失\n",
    "            loss = criterion(y_hat, labels)\n",
    "            # 反向传播\n",
    "            loss.backward()\n",
    "            # 更新参数\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        # 打印每个 epoch 的损失\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader)}\"\n",
    "        )\n",
    "        # 每个 epoch 结束后重置 running_loss\n",
    "        running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import argmax\n",
    "from numpy import vstack\n",
    "from sklearn.metrics import accuracy_score\n",
    "# 评估模型\n",
    "\n",
    "\n",
    "def evaluate_model(test_loader, model):\n",
    "    predictions, actuals = list(), list()\n",
    "    for i, (inputs, labels) in enumerate(test_loader):\n",
    "        # 将数据移动到GPU\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # 计算模型输出\n",
    "        y_hat = model(inputs)\n",
    "        # 转换为 numpy 数据类型\n",
    "        y_hat = y_hat.detach().cpu().numpy()\n",
    "        actual = labels.cpu().numpy()\n",
    "        # 转换为类标签\n",
    "        y_hat = argmax(y_hat, axis=1)\n",
    "        # 为stack格式化\n",
    "        actual = actual.reshape((len(actual), 1))\n",
    "        y_hat = y_hat.reshape((len(y_hat), 1))\n",
    "        # 存储\n",
    "        predictions.append(y_hat)\n",
    "        actuals.append(actual)\n",
    "    predictions, actuals = vstack(predictions), vstack(actuals)\n",
    "    # 计算准确率\n",
    "    acc = accuracy_score(actuals, predictions)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 产生实例,并且将实例放入GPU\n",
    "MNIST_Net_model = MNIST_Net()\n",
    "MNIST_Net_model.to(device)\n",
    "# 训练实例\n",
    "train_model(train_loader, MNIST_Net_model)\n",
    "# 评估实例\n",
    "acc = evaluate_model(test_loader, MNIST_Net_model)\n",
    "print('Accuracy: %.3f' % acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
