{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "训练集的 batch 数量: 391，每个 batch 中的数据数量: 128\n",
      "测试集的 batch 数量: 79，每个 batch 中的数据数量: 128\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "# 下载数据集的路径\n",
    "path = './DataSet'\n",
    "# 使用的设备\n",
    "device = torch.device(\"cuda\")\n",
    "# 数据预处理,转换为张量并归一化\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 将图像大小调整为 224x224\n",
    "    transforms.ToTensor(),  # 将图像转换为张量\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])  # 归一化处理\n",
    "\n",
    "train_set = CIFAR10(root=path, train=True, download=True, transform=transform)\n",
    "test_set = CIFAR10(root=path, train=False, download=True, transform=transform)\n",
    "# 加载数据集并设置批次大小\n",
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=128, shuffle=False)\n",
    "# 修正 print 语句，明确输出内容\n",
    "print(\n",
    "    f\"训练集的 batch 数量: {len(train_loader)}，每个 batch 中的数据数量: {train_loader.batch_size}\")\n",
    "print(\n",
    "    f\"测试集的 batch 数量: {len(test_loader)}，每个 batch 中的数据数量: {test_loader.batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Module\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Flatten\n",
    "from torch.nn import Sequential\n",
    "from torch.nn import BatchNorm2d\n",
    "from torch.nn import AdaptiveAvgPool2d\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.nn.init import xavier_uniform_\n",
    "\n",
    "# 启用异常检测\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "\n",
    "class ResNet(Module):\n",
    "    class Residual(Module):\n",
    "        def __init__(self, input_channels, num_channels, use_1x1conv=False, strides=1):\n",
    "            super().__init__()\n",
    "            self.features = Sequential(\n",
    "                Conv2d(input_channels, num_channels, kernel_size=3,padding=1, stride=strides, bias=False),\n",
    "                BatchNorm2d(num_channels),  # 第一个批量归一化\n",
    "                ReLU(),\n",
    "                Conv2d(num_channels, num_channels,kernel_size=3, padding=1, bias=False),\n",
    "                BatchNorm2d(num_channels),  # 第二个批量归一化\n",
    "            )\n",
    "            if use_1x1conv:\n",
    "                self.conv3 = Conv2d(input_channels, num_channels, kernel_size=1, stride=strides, bias=False)\n",
    "            else:\n",
    "                self.conv3 = None\n",
    "\n",
    "        def forward(self, X):\n",
    "            Y = self.features(X)\n",
    "            if self.conv3:\n",
    "                X = self.conv3(X)\n",
    "            # 将原地操作改为非原地操作\n",
    "            Y = Y + X\n",
    "            return ReLU()(Y)\n",
    "\n",
    "    def ResNet_Block(self, input_channels, num_channels, num_residuals, first_block=False):\n",
    "        blk = []\n",
    "        for i in range(num_residuals):\n",
    "            if i == 0 and not first_block:\n",
    "                blk.append(self.Residual(input_channels,num_channels, use_1x1conv=True, strides=2))\n",
    "            else:\n",
    "                blk.append(self.Residual(num_channels, num_channels))\n",
    "        return blk\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.features = Sequential(\n",
    "            Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            BatchNorm2d(64),\n",
    "            ReLU(),\n",
    "            MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            *self.ResNet_Block(64, 64, 2, first_block=True),\n",
    "            *self.ResNet_Block(64, 128, 2),\n",
    "            *self.ResNet_Block(128, 256, 2),\n",
    "            *self.ResNet_Block(256, 512, 2)\n",
    "        )\n",
    "        # 对特征提取部分的卷积层进行 Kaiming 初始化\n",
    "        for layer in self.features:\n",
    "            if isinstance(layer, Conv2d):\n",
    "                kaiming_uniform_(layer.weight, nonlinearity='relu')\n",
    "                if layer.bias is not None:\n",
    "                    torch.nn.init.zeros_(layer.bias)\n",
    "        self.classifier = Sequential(\n",
    "            AdaptiveAvgPool2d((1, 1)),\n",
    "            Flatten(),\n",
    "            Linear(512, num_classes)\n",
    "        )\n",
    "        # 对分类部分的全连接层进行 Xavier 初始化\n",
    "        for layer in self.classifier:\n",
    "            if isinstance(layer, Linear):\n",
    "                xavier_uniform_(layer.weight)\n",
    "                if layer.bias is not None:\n",
    "                    torch.nn.init.zeros_(layer.bias)\n",
    "    def forward(self, X):\n",
    "        X = self.features(X)\n",
    "        X = self.classifier(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "# 定义损失函数和优化器\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD\n",
    "import time\n",
    "\n",
    "def train_model(train_loader, model):\n",
    "    # 定义损失函数和优化器\n",
    "    criterion = CrossEntropyLoss()\n",
    "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    # 训练的轮数\n",
    "    num_epochs = 10\n",
    "    # 初始化 running_loss\n",
    "    running_loss = 0.0\n",
    "    # 记录训练开始时间\n",
    "    start_time = time.time()\n",
    "    # 遍历epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        # 遍历训练数据\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            # 将数据移动到GPU\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # 梯度清零\n",
    "            optimizer.zero_grad()\n",
    "            # 计算模型输出\n",
    "            y_hat = model(inputs)\n",
    "            # 计算损失\n",
    "            loss = criterion(y_hat, labels)\n",
    "            # 反向传播\n",
    "            loss.backward()\n",
    "            # 更新参数\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        # 打印每个 epoch 的损失\n",
    "        print(\n",
    "            f'Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader)}')\n",
    "        # 每个 epoch 结束后重置 running_loss\n",
    "        running_loss = 0.0\n",
    "    # 记录训练结束时间\n",
    "    end_time = time.time()\n",
    "    # 计算训练总时间\n",
    "    total_time = end_time - start_time\n",
    "    # 转换为分钟和秒\n",
    "    minutes = int(total_time // 60)\n",
    "    seconds = total_time % 60\n",
    "    print(\n",
    "        f'Training completed in {minutes} minutes and {seconds:.2f} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估模型\n",
    "from sklearn.metrics import accuracy_score\n",
    "from numpy import vstack\n",
    "from numpy import argmax\n",
    "\n",
    "\n",
    "def evaluate_model(test_loader, model):\n",
    "    predictions, actuals = list(), list()\n",
    "    for i, (inputs, labels) in enumerate(test_loader):\n",
    "        # 将数据移动到GPU\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # 计算模型输出\n",
    "        y_hat = model(inputs)\n",
    "        # 转换为 numpy 数据类型\n",
    "        y_hat = y_hat.detach().cpu().numpy()\n",
    "        actual = labels.cpu().numpy()\n",
    "        # 转换为类标签\n",
    "        y_hat = argmax(y_hat, axis=1)\n",
    "        # 为stack格式化\n",
    "        actual = actual.reshape((len(actual), 1))\n",
    "        y_hat = y_hat.reshape((len(y_hat), 1))\n",
    "        # 存储\n",
    "        predictions.append(y_hat)\n",
    "        actuals.append(actual)\n",
    "    predictions, actuals = vstack(predictions), vstack(actuals)\n",
    "    # 计算准确率\n",
    "    acc = accuracy_score(actuals, predictions)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.5159172130667644\n",
      "Epoch 2/10, Loss: 0.8547616166531887\n",
      "Epoch 3/10, Loss: 0.5726957867669937\n",
      "Epoch 4/10, Loss: 0.40920635867301763\n",
      "Epoch 5/10, Loss: 0.28179261267490097\n",
      "Epoch 6/10, Loss: 0.1763498827414897\n",
      "Epoch 7/10, Loss: 0.10806727696143453\n",
      "Epoch 8/10, Loss: 0.06497237058427861\n",
      "Epoch 9/10, Loss: 0.042235833003192835\n",
      "Epoch 10/10, Loss: 0.02562270505125146\n",
      "Training completed in 12 minutes and 38.90 seconds.\n",
      "Overall Accuracy: 0.841\n"
     ]
    }
   ],
   "source": [
    "# 产生实例,并且将实例放入GPU\n",
    "ResNet_model = ResNet(num_classes=10).to(device)\n",
    "# 训练实例\n",
    "train_model(train_loader, ResNet_model)\n",
    "# 评估实例整体准确率\n",
    "acc = evaluate_model(test_loader, ResNet_model)\n",
    "print('Overall Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存训练好的模型\n",
    "PATH = './DataSet/model/ResNet_model.pth'\n",
    "torch.save(ResNet_model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for plane: 87.5%\n",
      "Accuracy for car  : 93.0%\n",
      "Accuracy for bird : 78.4%\n",
      "Accuracy for cat  : 65.7%\n",
      "Accuracy for deer : 82.1%\n",
      "Accuracy for dog  : 79.0%\n",
      "Accuracy for frog : 91.6%\n",
      "Accuracy for horse: 86.2%\n",
      "Accuracy for ship : 89.8%\n",
      "Accuracy for truck: 91.4%\n"
     ]
    }
   ],
   "source": [
    "ResNet_model = ResNet(num_classes=10).to(device)\n",
    "ResNet_model.load_state_dict(torch.load(PATH, weights_only=True))\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "# 初始化分类准确率统计\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# 评估每个类别的准确率\n",
    "with torch.no_grad():\n",
    "    ResNet_model.eval()  # 确保模型处于评估模式\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        # 将数据移动到GPU\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = ResNet_model(images)  # 使用实例化模型\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "        # 将预测结果和标签移动到CPU并转换为numpy数组\n",
    "        labels = labels.cpu().numpy()\n",
    "        predictions = predictions.cpu().numpy()\n",
    "\n",
    "        for label_idx, pred_idx in zip(labels, predictions):\n",
    "            class_name = classes[label_idx]\n",
    "            if label_idx == pred_idx:\n",
    "                correct_pred[class_name] += 1\n",
    "            total_pred[class_name] += 1\n",
    "\n",
    "# 打印每个类别的准确率\n",
    "for classname in classes:\n",
    "    total = total_pred[classname]\n",
    "    correct = correct_pred[classname]\n",
    "    if total == 0:\n",
    "        print(f\"Class {classname} has no test samples\")\n",
    "        continue\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy for {classname:5s}: {accuracy:.1f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
