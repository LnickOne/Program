{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "# 下载数据集的路径\n",
    "path = './DataSet'\n",
    "# 使用的设备\n",
    "device = torch.device(\"cuda\")\n",
    "# 数据预处理,转换为张量并归一化\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 将图像大小调整为 224x224\n",
    "    transforms.ToTensor(),  # 将图像转换为张量\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])  # 归一化处理\n",
    "\n",
    "train_set = CIFAR10(root=path, train=True, download=True, transform=transform)\n",
    "test_set = CIFAR10(root=path, train=False, download=True, transform=transform)\n",
    "# 加载数据集并设置批次大小\n",
    "train_loader = DataLoader(train_set, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=256, shuffle=False)\n",
    "# 打印数据集的信息\n",
    "print(\n",
    "    f\"训练集的 batch 数量: {len(train_loader)}，每个 batch 中的数据数量: {train_loader.batch_size}\")\n",
    "print(\n",
    "    f\"测试集的 batch 数量: {len(test_loader)}，每个 batch 中的数据数量: {test_loader.batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Module\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Flatten\n",
    "from torch.nn import Sequential\n",
    "from torch.nn import BatchNorm2d\n",
    "from torch.nn import AdaptiveAvgPool2d\n",
    "from torch.nn import AvgPool2d\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.nn.init import xavier_uniform_\n",
    "\n",
    "\n",
    "class DenseNet(Module):\n",
    "    class DenseBlock(Module):\n",
    "        def DenseNet_block(self, input_channels, num_channels):\n",
    "            return Sequential(\n",
    "                BatchNorm2d(input_channels),\n",
    "                ReLU(),\n",
    "                Conv2d(input_channels, num_channels, kernel_size=3, padding=1)\n",
    "            )\n",
    "        def transition_block(self, input_channels, num_channels):\n",
    "            return Sequential(\n",
    "                BatchNorm2d(input_channels),\n",
    "                ReLU(),\n",
    "                Conv2d(input_channels, num_channels, kernel_size=1),\n",
    "                AvgPool2d(kernel_size=2, stride=2)\n",
    "            )\n",
    "\n",
    "        def __init__(self, num_convs, input_channels, num_channels):\n",
    "            super().__init__()\n",
    "            layer = []\n",
    "            for i in range(num_convs):\n",
    "                layer.append(self.DenseNet_block(num_channels * i + input_channels, num_channels))\n",
    "            self.net = Sequential(*layer)\n",
    "\n",
    "        def forward(self, X):\n",
    "            for blk in self.net:\n",
    "                Y = blk(X)\n",
    "                X = torch.cat((X, Y), dim=1)\n",
    "            return X\n",
    "\n",
    "    def __init__(self, num_classes, num_dense_blocks=4, num_convs_per_block=4, growth_rate=32):\n",
    "        super().__init__()\n",
    "        self.features = Sequential(\n",
    "            Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "            BatchNorm2d(64),\n",
    "            ReLU(),\n",
    "            MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        num_channels = 64\n",
    "        for i in range(num_dense_blocks):\n",
    "            dense_block = self.DenseBlock(num_convs_per_block, num_channels, growth_rate)\n",
    "            self.features.add_module(f'dense_block_{i}', dense_block)\n",
    "            num_channels += num_convs_per_block * growth_rate\n",
    "            if i != num_dense_blocks - 1:\n",
    "                # 通过实例调用 transition_block 方法\n",
    "                transition = dense_block.transition_block(num_channels, num_channels // 2)\n",
    "                self.features.add_module(f'transition_block_{i}', transition)\n",
    "                # 将 num_channels 的值更新为原来的一半\n",
    "                num_channels = num_channels // 2\n",
    "        self.features.add_module('global_avg_pool', AdaptiveAvgPool2d((1, 1)))\n",
    "        self.classifier = Sequential(\n",
    "            Flatten(),\n",
    "            Linear(num_channels, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "# 定义损失函数和优化器\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD\n",
    "import time\n",
    "\n",
    "\n",
    "def train_model(train_loader, model):\n",
    "    # 定义损失函数和优化器\n",
    "    criterion = CrossEntropyLoss()\n",
    "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    # 训练的轮数\n",
    "    num_epochs = 10\n",
    "    # 初始化 running_loss\n",
    "    running_loss = 0.0\n",
    "    # 记录训练开始时间\n",
    "    start_time = time.time()\n",
    "    # 遍历epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        # 遍历训练数据\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            # 将数据移动到GPU\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # 梯度清零\n",
    "            optimizer.zero_grad()\n",
    "            # 计算模型输出\n",
    "            y_hat = model(inputs)\n",
    "            # 计算损失\n",
    "            loss = criterion(y_hat, labels)\n",
    "            # 反向传播\n",
    "            loss.backward()\n",
    "            # 更新参数\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        # 打印每个 epoch 的损失\n",
    "        print(\n",
    "            f'Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader)}')\n",
    "        # 每个 epoch 结束后重置 running_loss\n",
    "        running_loss = 0.0\n",
    "    # 记录训练结束时间\n",
    "    end_time = time.time()\n",
    "    # 计算训练总时间\n",
    "    total_time = end_time - start_time\n",
    "    # 转换为分钟和秒\n",
    "    minutes = int(total_time // 60)\n",
    "    seconds = total_time % 60\n",
    "    print(\n",
    "        f'Training completed in {minutes} minutes and {seconds:.2f} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估模型\n",
    "from sklearn.metrics import accuracy_score\n",
    "from numpy import vstack\n",
    "from numpy import argmax\n",
    "\n",
    "\n",
    "def evaluate_model(test_loader, model):\n",
    "    predictions, actuals = list(), list()\n",
    "    for i, (inputs, labels) in enumerate(test_loader):\n",
    "        # 将数据移动到GPU\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # 计算模型输出\n",
    "        y_hat = model(inputs)\n",
    "        # 转换为 numpy 数据类型\n",
    "        y_hat = y_hat.detach().cpu().numpy()\n",
    "        actual = labels.cpu().numpy()\n",
    "        # 转换为类标签\n",
    "        y_hat = argmax(y_hat, axis=1)\n",
    "        # 为stack格式化\n",
    "        actual = actual.reshape((len(actual), 1))\n",
    "        y_hat = y_hat.reshape((len(y_hat), 1))\n",
    "        # 存储\n",
    "        predictions.append(y_hat)\n",
    "        actuals.append(actual)\n",
    "    predictions, actuals = vstack(predictions), vstack(actuals)\n",
    "    # 计算准确率\n",
    "    acc = accuracy_score(actuals, predictions)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 产生实例,并且将实例放入GPU\n",
    "#DenseNet_model = DenseNet(num_classes=10).to(device)\n",
    "DenseNet_model2 = DenseNet(num_classes=10, num_dense_blocks=5, num_convs_per_block=5, growth_rate=48).to(device)\n",
    "# 训练实例\n",
    "train_model(train_loader, DenseNet_model2)\n",
    "# 评估实例整体准确率\n",
    "acc = evaluate_model(test_loader, DenseNet_model2)\n",
    "print('Overall Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存训练好的模型\n",
    "PATH = './DataSet/model/DenseNet_model2.pth'\n",
    "torch.save(DenseNet_model2.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DenseNet_model2 = DenseNet(num_classes=10, num_dense_blocks=5, num_convs_per_block=5, growth_rate=48).to(device)\n",
    "DenseNet_model2.load_state_dict(torch.load(PATH, weights_only=True))\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer','dog', 'frog', 'horse', 'ship', 'truck')\n",
    "# 初始化分类准确率统计\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# 评估每个类别的准确率\n",
    "with torch.no_grad():\n",
    "    DenseNet_model2.eval()  # 确保模型处于评估模式\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        # 将数据移动到GPU\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = DenseNet_model2(images)  # 使用实例化模型\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "        # 将预测结果和标签移动到CPU并转换为numpy数组\n",
    "        labels = labels.cpu().numpy()\n",
    "        predictions = predictions.cpu().numpy()\n",
    "\n",
    "        for label_idx, pred_idx in zip(labels, predictions):\n",
    "            class_name = classes[label_idx]\n",
    "            if label_idx == pred_idx:\n",
    "                correct_pred[class_name] += 1\n",
    "            total_pred[class_name] += 1\n",
    "\n",
    "# 打印每个类别的准确率\n",
    "for classname in classes:\n",
    "    total = total_pred[classname]\n",
    "    correct = correct_pred[classname]\n",
    "    if total == 0:\n",
    "        print(f\"Class {classname} has no test samples\")\n",
    "        continue\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy for {classname:5s}: {accuracy:.1f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
